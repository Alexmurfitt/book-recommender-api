import json
import unicodedata
import re
from pathlib import Path
from collections import defaultdict

# ------------------------------
# üîß Funciones de normalizaci√≥n
# ------------------------------

def normalize(text):
    if not isinstance(text, str):
        return None
    text = unicodedata.normalize("NFKD", text).casefold()
    text = re.sub(r"[\s\-_/]+", " ", text)  # Unifica separadores
    text = re.sub(r"[^\w\s]", "", text)     # Elimina puntuaci√≥n
    text = text.strip()
    return text if text not in {"", "n/a", "na", "null", "none"} else None

def normalize_list(values):
    if not isinstance(values, list):
        return []
    return [normalize(v) for v in values if normalize(v)]

# ------------------------------
# üì• Cargar libros
# ------------------------------

file_path = Path(__file__).resolve().parents[1] / "data" / "books_openlibrary_enriched.json"
with open(file_path, "r", encoding="utf-8") as f:
    books = json.load(f)

# ------------------------------
# üìä Inicializar contenedores
# ------------------------------

field_sets = defaultdict(set)
anomalies = []

# Campos objetivo
fields_list = [
    "genres", "subgenres", "themes", "emotion_tags", 
    "tone", "style", "age_range", "language"
]

# ------------------------------
# üîç Recorrer libros y extraer campos
# ------------------------------

for i, book in enumerate(books):
    for field in fields_list:
        value = book.get(field)

        if isinstance(value, list):
            cleaned = normalize_list(value)
            if not cleaned:
                anomalies.append((i, field, "LISTA VAC√çA O MAL FORMADA"))
            field_sets[field].update(cleaned)

        elif isinstance(value, str):
            norm = normalize(value)
            if not norm:
                anomalies.append((i, field, "CADENA VAC√çA O INV√ÅLIDA"))
            else:
                field_sets[field].add(norm)

        elif value is None:
            anomalies.append((i, field, "VALOR AUSENTE"))

        else:
            anomalies.append((i, field, f"TIPO INV√ÅLIDO: {type(value)}"))

# ------------------------------
# üíæ Guardar resultados
# ------------------------------

output_path = Path(__file__).resolve().parent / "field_options_cleaned.json"
with open(output_path, "w", encoding="utf-8") as f:
    json.dump({k: sorted(list(v)) for k, v in field_sets.items()}, f, ensure_ascii=False, indent=2)

# ------------------------------
# üìã Imprimir resumen riguroso
# ------------------------------

for field in fields_list:
    print(f"\nüìå {field.upper()} ({len(field_sets[field])} √∫nicos):")
    for v in sorted(field_sets[field]):
        print(f"  - {v}")

if anomalies:
    print("\n‚ö†Ô∏è ANOMAL√çAS DETECTADAS:")
    for idx, field, issue in anomalies:
        print(f"  - Libro #{idx} | Campo '{field}': {issue}")
else:
    print("\n‚úÖ Sin anomal√≠as detectadas.")
# ------------------------------
# üìù Guardar resumen en TXT
# ------------------------------

txt_output_path = Path(__file__).resolve().parent / "extract_fields.txt"
with open(txt_output_path, "w", encoding="utf-8") as f:
    for field in fields_list:
        f.write(f"\nüìå {field.upper()} ({len(field_sets[field])} √∫nicos):\n")
        for v in sorted(field_sets[field]):
            f.write(f"  - {v}\n")

    if anomalies:
        f.write("\n‚ö†Ô∏è ANOMAL√çAS DETECTADAS:\n")
        for idx, field, issue in anomalies:
            f.write(f"  - Libro #{idx} | Campo '{field}': {issue}\n")
    else:
        f.write("\n‚úÖ Sin anomal√≠as detectadas.\n")
