# ğŸ“š API de RecomendaciÃ³n de Libros Personalizada

**TecnologÃ­as:** FastAPI Â· MongoDB Â· PyMongo Â· Pydantic Â· Python Â· Postman

## ğŸ¯ Â¿En quÃ© consiste esta API?

Se trata de una API backend desarrollada con FastAPI y MongoDB cuyo objetivo es recomendar libros con precisiÃ³n y objetividad a cada usuario, combinando:

1. **ğŸ“ Cuestionario literario inteligente**, donde el usuario indica sus gÃ©neros favoritos, temas, emociones deseadas, tono y estilo narrativo, y edad lectora.
2. **ğŸ§  Test psicolÃ³gico basado en el modelo Big Five (OCEAN)**, que genera un perfil psicomÃ©trico con puntuaciones en apertura, responsabilidad, extraversiÃ³n, amabilidad y neuroticismo.
3. **âš™ï¸ Algoritmo heurÃ­stico de recomendaciÃ³n**, que compara el perfil completo del usuario con una base de datos enriquecida de 335 libros (67 subgÃ©neros, 11 gÃ©neros), para encontrar los libros mÃ¡s afines, acompaÃ±ados de una explicaciÃ³n textual del porquÃ©.

---

## ğŸ§± Estructura del proyecto

```
book_recommender_api/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              â† Punto de entrada FastAPI
â”‚   â”œâ”€â”€ database.py          â† ConexiÃ³n MongoDB con PyMongo
â”‚   â”œâ”€â”€ models.py            â† Esquemas Pydantic (UserProfile, Book, Personality, etc.)
â”‚   â”œâ”€â”€ quiz.py              â† Endpoint para preferencias literarias
â”‚   â”œâ”€â”€ personality.py       â† Endpoint para test OCEAN
â”‚   â”œâ”€â”€ profile.py           â† CombinaciÃ³n de quiz + personalidad
â”‚   â”œâ”€â”€ recommender.py       â† LÃ³gica de matching y puntuaciÃ³n
â”‚   â”œâ”€â”€ explain.py           â† GeneraciÃ³n de explicaciÃ³n semÃ¡ntica
â”‚   â”œâ”€â”€ books_controller.py  â† GestiÃ³n de libros (GET/POST)
â”œâ”€â”€ data/
â”‚   â””â”€â”€ books_all_335.json   â† Dataset enriquecido de libros
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ import_books.py      â† ImportaciÃ³n del dataset
â”‚   â””â”€â”€ create_project_structure.py
â”œâ”€â”€ requirements.txt         â† Dependencias del proyecto
â””â”€â”€ .env                     â† Variables de entorno (MONGO_URI)
```

---

## ğŸ§  LÃ³gica de recomendaciÃ³n

El algoritmo evalÃºa el perfil del usuario frente a cada libro con una fÃ³rmula ponderada:

```python
score = (
    0.4 * genre_match +
    0.3 * emotion_match +
    0.2 * personality_match +
    0.1 * style_tone_match
)
```

Se seleccionan los 5 libros con mayor puntuaciÃ³n y se genera una explicaciÃ³n transparente basada en coincidencias reales (gÃ©neros, emociones, personalidad, estilo).

---

## ğŸ§ª Endpoints implementados

| Endpoint                  | MÃ©todo   | DescripciÃ³n                                                     |
| ------------------------- | -------- | --------------------------------------------------------------- |
| `/quiz`                   | POST     | Guarda las respuestas del cuestionario literario                |
| `/personality-test`       | POST     | Guarda el perfil OCEAN del usuario                              |
| `/user-profile`           | POST     | Combina preferencias y personalidad en un perfil Ãºnico          |
| `/recommendation`         | GET      | Devuelve los libros mÃ¡s compatibles con el perfil del usuario   |
| `/explain-recommendation` | GET      | Devuelve explicaciÃ³n detallada del porquÃ© de cada recomendaciÃ³n |
| `/books`                  | GET/POST | Consultar o aÃ±adir libros a la base de datos                    |

---

## ğŸ”§ QuÃ© he implementado paso a paso

1. **DiseÃ±o y estructura del sistema**

   * CreaciÃ³n de arquitectura modular siguiendo patrÃ³n MVC.
   * SeparaciÃ³n de la lÃ³gica por responsabilidad (quiz, personalidad, perfil, recomendaciÃ³n, explicaciÃ³n, base de datos).
   * Uso de clases Pydantic para modelado de datos validado.

2. **GestiÃ³n de usuarios y perfiles**

   * Registro por ID Ãºnico (UUID) y validaciÃ³n de email.
   * Almacenamiento de quiz y test OCEAN por usuario.
   * ComposiciÃ³n del perfil completo combinando ambas respuestas.

3. **Dataset enriquecido**

   * SelecciÃ³n manual y estructurada de 335 libros reales desde Open Library, Goodreads, etc.
   * ClasificaciÃ³n por gÃ©nero, subgÃ©nero, temas, emociones, estilo, tono, idioma, edad lectora y personalidad compatible.
   * ImportaciÃ³n a MongoDB y validaciÃ³n de formato con `jq`.

4. **Desarrollo del sistema de recomendaciÃ³n**

   * ImplementaciÃ³n del motor de puntuaciÃ³n heurÃ­stica (`compute_score`).
   * Filtro por idioma, edad y afinidad semÃ¡ntica.
   * GeneraciÃ³n automÃ¡tica de explicaciones (`generate_explanation`) con campos coincidentes.

5. **Testing y resoluciÃ³n de errores**

   * Pruebas exhaustivas con Postman.
   * ValidaciÃ³n de integridad de la base de datos en MongoDB Compass.
   * CorrecciÃ³n de mÃºltiples errores: rutas incorrectas, conflictos de dependencias, incompatibilidad con Python 3.13 (migraciÃ³n a 3.10), uso de `__init__.py`, normalizaciÃ³n de imports absolutos.

---

## ğŸ§¯ Problemas tÃ©cnicos superados

| Problema                                   | SoluciÃ³n aplicada                                         |
| ------------------------------------------ | --------------------------------------------------------- |
| `ModuleNotFoundError` con `utils` o `quiz` | Uso de imports absolutos y archivos `__init__.py`         |
| Conflicto con `pydantic 2.x`               | MigraciÃ³n estable a `pydantic 1.10.13`                    |
| Error con `uvicorn` al lanzar la app       | Cambio a ejecuciÃ³n desde raÃ­z con ruta explÃ­cita correcta |
| MongoDB no conectado                       | AÃ±adido endpoint `/ping` para comprobaciÃ³n                |

---

## âœ… Conocimientos y habilidades adquiridas

âœ”ï¸ DiseÃ±o de APIs RESTful con FastAPI
âœ”ï¸ Modelado y validaciÃ³n de datos con Pydantic
âœ”ï¸ ConexiÃ³n y manipulaciÃ³n de datos en MongoDB con PyMongo
âœ”ï¸ DiseÃ±o de sistemas de recomendaciÃ³n heurÃ­sticos
âœ”ï¸ Testing con Postman
âœ”ï¸ DepuraciÃ³n de errores y despliegue en entorno local
âœ”ï¸ OrganizaciÃ³n modular y buenas prÃ¡cticas de ingenierÃ­a backend

---

## ğŸŒŸ ConclusiÃ³n final

Este proyecto representa una soluciÃ³n profesional, robusta y escalable para la recomendaciÃ³n de contenido cultural personalizado. He trabajado desde cero en la arquitectura, diseÃ±o, implementaciÃ³n, depuraciÃ³n y validaciÃ³n de todos los mÃ³dulos necesarios para que el sistema funcione con precisiÃ³n y eficiencia. Es un ejemplo claro de cÃ³mo integrar procesamiento semÃ¡ntico, evaluaciÃ³n psicomÃ©trica y estructuraciÃ³n de datos para ofrecer recomendaciones realmente inteligentes.

Este sistema puede escalarse fÃ¡cilmente con un frontend en Streamlit o React, autenticaciÃ³n JWT, clustering de usuarios, sinopsis generadas por IA, y recomendaciones multilingÃ¼es.


